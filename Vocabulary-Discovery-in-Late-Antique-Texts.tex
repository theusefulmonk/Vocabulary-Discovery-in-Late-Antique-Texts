% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
]{tufte-handout}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{listings}
\newcommand{\passthrough}[1]{#1}
\lstset{defaultdialect=[5.3]Lua}
\lstset{defaultdialect=[x86masm]Assembler}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{255,255,255}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.75,0.01,0.01}{\textbf{\colorbox[rgb]{0.97,0.90,0.90}{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.79,0.38,0.79}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.00,0.34,0.68}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.69,0.50,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.39,0.29,0.61}{\textbf{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.57,0.30,0.62}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.54,0.53,0.53}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.00,0.58,1.00}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.67,0.33,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.12,0.11,0.11}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.00,0.34,0.68}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.69,0.50,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.38,0.47,0.50}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.75,0.01,0.01}{\underline{#1}}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.58,1.00}{\textbf{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.69,0.50,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.39,0.29,0.61}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{1.00,0.33,0.00}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.69,0.50,0.00}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.12,0.11,0.11}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.12,0.11,0.11}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.12,0.11,0.11}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.43,0.16}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.00,0.43,0.16}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.34,0.68}{\colorbox[rgb]{0.88,0.91,0.97}{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.24,0.68,0.91}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{1.00,0.33,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.75,0.01,0.01}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.34,0.68}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.75,0.01,0.01}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.75,0.01,0.01}{#1}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
%\usepackage[svgnames]{xcolor}
%\definecolor{codebackground}{RGB}{240, 240, 235}
%\definecolor{codebackground}{RGB}{117, 128, 124}
%\AtBeginDocument{\colorlet{defaultcolor}{.}}
%\definecolor{bg}{HTML}{282828} % from https://github.com/kevinsawicki/monokai
%\usepackage[outputdir=build]{minted}
%\setminted{style=monokai,bgcolor=bg}
%\setmintedinline{style=monokai,bgcolor=None}
%\definecolor{Text}{HTML}{F8F8F2}
%\AddToHook{cmd/mintinline/before}{\color{Text}}
%\AddToHook{cmd/mintinline/after}{}
    %\AtBeginEnvironment{minted}{\color{Text}}
\usepackage{pgfornament}
\usepackage{setspace}
\usepackage{microtype}
\usepackage{fontspec}
    \defaultfontfeatures{Numbers=OldStyle}
    \setmainfont{STIX Two Text}
\setmonofont{PragmataPro Mono Liga}
%\renewcommand{\footnote}[1]{\sidenote{#1}}
%\renewcommand{\familydefault}{\sfdefault}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Efficient Vocabulary Discovery in Late Antique Texts at the UNIX Command Line},
  pdfauthor={Andrew J. Hayes},
  colorlinks=true,
  linkcolor={teal},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}

\title{Efficient Vocabulary Discovery in Late Antique Texts at the UNIX
Command Line}
\author{Andrew J. Hayes}
\date{May 23, 2025}

\begin{document}
\maketitle

\ifdefined\soulregister

\soulregister\MakeTextUppercase{1} \soulregister\MakeTextLowercase{1}
\soulregister\newlinetospace{1} \fi

\section{Introduction}\label{introduction}

I present this workflow first by identifying the use cases for it and
outlining the goals this presentation hopes to achieve and those it does
not. A conceptual overview follows, with the aim of providing just
enough background knowledge to use the workflow. I present the workflow
in overview and interactively demonstrate its core steps. I conclude by
highlighting the workflow's limitations and imparting further resources
that will enable interested attendees to experiment with the workflow
themselves.

\section{Use Cases}\label{use-cases}

The workflow demonstrated here is designed to address a particular
difficulty in patristic scholarship: searching ancient text(s) (whether
in the original or in translation) for which no born digital search tool
is available or accessible. Many collections of primary sources have
such tools. The \href{https://syriaccorpus.org/index.html}{Digital
Syriac Corpus} is an example of a native digital collection with robust
search tools. The \href{https://stephanus.tlg.uci.edu}{Thesaurus Linguae
Graecae} is another. Using such tools, if available, is ordinarily
preferrable to the approach described in this presentation.

But what to do if no such tool exists, is pay-walled, or is inaccessible
for some other reason? Many scholars maintain their own corpora of
scanned pdfs for private research use. Optical character recognition
(OCR) makes digital search of such texts possible. This presentation
shows how to search a local directory tree of OCR'ed pdf files of
primary sources in original or in translation in an efficient manner
using freely available tools in the UNIX programming environment. These
methods are imperfect, but nevertheless highly useful for assembling a
working vocabulary list as a starting point for careful reading and
research. Accompanying this presentation is a
\href{==insert\%20link==}{public repository on github} with sample
command-line recipes and instructions allowing any scholar to download
and experiment with them.

Note thate even when a native digital search tool is available, it is
sometimes convenient and practical to employ the tools and techniques
presented here. The following are four such cases:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  One wants to search a large number of pdf files from disparate corpora
  at once.
\item
  One wants to search in multiple languages simultaneously.
\item
  One wants to automate or script complex queries for reproducibility
  and convenience.
\item
  One wants to produce a customized report of search results for use in
  another application.
\end{enumerate}

The examples in this talk involve searching Ephrem the Syrian's corpus,
mostly in the form of Edmund Beck's German translations, using scans
made for personal use from purchased physical volumes. The tools and
techniques are, however, applicable to any pdf containing LTR text in a
Roman or Greek alphabet, or any such script supported by a terminal
emulator.

\section{Three Core Steps (Goals and
Non-Goals)}\label{three-core-steps-goals-and-non-goals}

These workflows are complex. It is impossible to describe all their
parts fully within the scope of this presentation. Some of the parts
omitted from the main discussion are identified and augmented in the
Github repository with hints and suggestions for how one might best
accomplish the task. Nevertheless, the main business of this talk is to
discuss the three core steps in the workflow:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Repaginate
\item
  Explore
\item
  Report
\end{enumerate}

\section{Background}\label{background}

\subsection{UNIX and the Command Line}\label{unix-and-the-command-line}

UNIX is a family of operating systems descended from an operating system
developed at Bell Labs in the 1970s.\footnote{Brian W. Kernighan and Rob
  Pike, \emph{The UNIX Programming Environment} (Englewood Cliffs, New
  Jersey: Prentice-Hall, 1984), vii.} Its original headline feature was
the ability to provide robust multi-user support in a way that clearly
delineated user ownership of files to prevent conflicts.\footnote{Kernighan
  and Pike, \emph{The UNIX Programming Environment}, 1.} It eventually
became a kind of standard: POSIX, the Portable Operating System
Interface.\footnote{Arnold Robbins and Nelson H. F. Beebe, \emph{Classic
  Shell Scripting: Hidden Commands That Unlock the Power of Unix}
  (Sebastapol, California: {``O'Reilly Media, Inc.''} 2005), 1--7.}
Today, MacOS and various forms of Linux and BSD are the most commonly
used UNIXes. They form the backbone of the internet. Most servers run
some form of UNIX.

UNIX OS's share a common structural feature: they consist of a kernel
and a shell. A shell is a textual interface for users to the kernel of
the OS. The shell is a command interpreter. It provides a prompt and a
command language allowing the user to issue written commands to the
kernel and to orchestrate the operation of many programs simultaneously.
Although there are many different shells available to a user, most
implement some substantial portion of the POSIX standard, which means
that a user who learns one shell can usually apply that knowledge to any
UNIX installation. The tools discussed in this presentation are as
standard as possible and should be available for any UNIX system.

On modern desktop and laptop computers with a window-based graphical
user interface, the user accesses the shell through a terminal emulator
program, which provides a place in which to issue commands via the shell
and to receive output from those commands. Commands are issued to the
shell as lines of plain text. This constitutes the Command Line
Interface (CLI). We will be extracting information from pdf files and
manipulating it at the command line using the tools
\VERB|\ExtensionTok{pdfgrep}|, \VERB|\FunctionTok{grep}|,
\VERB|\FunctionTok{awk}|, and \VERB|\ExtensionTok{lualatex}|.\footnote{Other
  forms of \LaTeX, such as \VERB|\ExtensionTok{pdflatex}| and
  \VERB|\ExtensionTok{xelatex}| will serve just as well.} Some
information about how to install \VERB|\ExtensionTok{pdfgrep}| via
common package managers and \VERB|\ExtensionTok{lualatex}| as part of a
\TeX distribution is provided in the acommpanying repository. The tools
\VERB|\FunctionTok{grep}| and \VERB|\FunctionTok{awk}| are already
included in any POSIX compliant environment. Any standard shell may be
used. My examples will use \VERB|\FunctionTok{zsh}|, the default in
MacOS.

One important feature of UNIX tools is their composability. They can be
chained together into a pipeline to achieve a series of transformations
producing the desired result. Textual information flows through UNIX
commands like water flows through a pipe.

\subsection{Key Concepts: PDF Page Labels and Regular
Expressions}\label{key-concepts-pdf-page-labels-and-regular-expressions}

The heart of this workflow turns on two key concepts: pdf page labels
and regular expressions. Such regexes, as they are called will not
receive their own tutorial here, but simple examples in the
demonstration portion will illustrate how they are used. Resources for
further study are available in the associated github repository. In
essence, a regex is a plain text string that represents a pattern. A
regex engine evaluates that string and finds all the strings in the
source document that match the pattern. As originally conceived, regexes
are used by a tool such as \VERB|\FunctionTok{grep}| to search one or
more plain text files. The tool \VERB|\ExtensionTok{pdfgrep}| is a free
and open-source variant of \VERB|\FunctionTok{grep}| that makes it
possible to search a pdf file. Like \VERB|\FunctionTok{grep}| the
\VERB|\ExtensionTok{pdfgrep}| tool is given a regex and one or more
source files and outputs all the matches, along with useful context for
the match: for instance, the filename of the source file in which the
match occurs and the pdf page label of the page on which the match
occurs.

Page labels are a form of metadata in a pdf file that are displayed by
most pdf viewing software, such as MacOS
\VERB|\ExtensionTok{Preview.app}| or KDE \VERB|\ExtensionTok{Okular}|.
They usually indicate a digital text's logical page number corresponding
to its printed original. As in a printed text, cover pages, frontmatter,
body, and backmatter can have distinct pagination. Thus, frontmatter
might be paginated with lowercase roman numerals, while the body might
have arabic numerals. As a result, a given page might, in absolute
terms, be the seventh page in a pdf document, but be labeled with the
number 2 because it has been preceded by a cover page and pages i-iv of
frontmatter. The PDF Association describes these labels as ``an optional
descriptive label of a page that is commonly presented on-screen. This
is in contrast to the integer page index used internally in PDF
files.''\footnote{PDF Association, {``Glossary of PDF Terms''}
  (\url{https://pdfa.org/glossary-of-pdf-terms/\#p}, 2025).} Such labels
are useful for working with a digital version in concert with its
printed \emph{Vorlage}.

Correspondence to the printed original is key to this workflow. If the
labels of the scanned pdf correspond correctly to the printed original,
the list of matches produced by \VERB|\ExtensionTok{pdfgrep}| can easily
be looked up in either the digital or printed version. Moreover, PDF
viewer software typically provides a keyboard shortcut to jump directly
to a specified page label, a feature that is important when scanned
files run to hundreds of pages and lack other forms of navigable
structure.

Unfortunately, a dumb scan of the printed original needs the page labels
added, and most free viewers provide limited functionality, or none at
all, for editing page label metadata or page order. Hence the first step
in the workflow is to repaginate using \LaTeX. We turn now to the
workflow.

\section{Workflow}\label{workflow}

\subsection{Pre-requisite steps}\label{pre-requisite-steps}

We take for granted here that you already have one or more ocr'ed pdf
files that meet the following requirements

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  scanned at 300 dpi or better;
\item
  OCR'ed using a high quality OCR engine (Abby recommended);
\item
  and single page: each page of the hard-copy corresponds to a single
  page in the pdf.
\end{enumerate}

\subsection{Repaginate}\label{repaginate}

We will use the accompanying file \VERB|\NormalTok{repaginate.tex}|. We
start with the scanned pdf's that need repagination in the same
directory as \VERB|\NormalTok{repaginate.tex}|. We then make any
necessary changes to the \VERB|\NormalTok{repaginate.tex}| file.

If the original file is Beck's translation of the \emph{Hymns on the
Church} with the filename \VERB|\NormalTok{beck\_1960.pdf}|, then we
first examine the scan to determine the absolute page numbers of each
section requiring distinct pagination:

\begin{itemize}
\tightlist
\item
  1-6 should be numbered i-vi
\item
  7-end should be numbered 7-146
\end{itemize}

In \VERB|\NormalTok{repaginate.tex}| we comment out lines 38-39 because
we don't need any cover pages. Then, we change line 54 to include pages
1-6, and the filename to \VERB|\NormalTok{sources/beck\_1960.pdf}|. We
change line 57 to include the rest of the pages 7-end using the string
\VERB|\NormalTok{7{-}}|. Once again we must update the filename to
\VERB|\NormalTok{sources/beck\_1960.pdf}|. This will compile a new pdf
with the specified pages, using the specified page labels.

The final compilation results from the following command:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{lualatex}\NormalTok{ repaginate.tex}
\end{Highlighting}
\end{Shaded}

The result should be a pdf file with the correct page labels.

At this point the file is ready to use for searches. However, for this
demonstration we are also going to establish a file naming convention
that will help produce a useful report at the end. The convention is
convenient, but arbitrary, and is necessary only if you want to use my
\VERB|\FunctionTok{awk}| script without modification. You are free to
re-write it to follow some other convention. The included
\VERB|\FunctionTok{awk}| script is designed to use pdfs with filenames
that begin with an abbreviation designating the collection, followed by
a space, followed by any other text. For example, if one has the
\emph{Hymns on the Church}, the \emph{Hymns on Faith}, and the
\emph{Metrical Discourses on Faith}, the filenames for each would be:
\VERB|\NormalTok{HdE }\DataTypeTok{\textless{}}\KeywordTok{whatever}\DataTypeTok{\textgreater{}}\NormalTok{.pdf}|
and
\VERB|\NormalTok{HdF }\DataTypeTok{\textless{}}\KeywordTok{whatever}\DataTypeTok{\textgreater{}}\NormalTok{.pdf}|
and
\VERB|\NormalTok{SdF }\DataTypeTok{\textless{}}\KeywordTok{whatever}\DataTypeTok{\textgreater{}}\NormalTok{.pdf}|.

\subsection{Explore}\label{explore}

Following the UNIX philosophy, we first compose small searches
interactively at the command line. Once one has worked out the pieces,
they can be put together into a single pipeline.

\textbf{Getting a list of matches}

This basic search shows how regular expressions can be useful for
capturing text with and without diacriticals, and for capturing
compounds:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{pdfgrep} \AttributeTok{{-}e} \StringTok{\textquotesingle{}[Ss]ch[aä]tz\textquotesingle{}}\NormalTok{ HdE}\DataTypeTok{\textbackslash{} }\NormalTok{German.pdf }\AttributeTok{{-}H} \AttributeTok{{-}{-}page{-}number}\OperatorTok{=}\NormalTok{label}
\end{Highlighting}
\end{Shaded}

Using the \VERB|\ExtensionTok{{-}H}| option forces the filename to be
output when there is only a single text being searched.

\textbf{Counting the number of matches}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{pdfgrep} \AttributeTok{{-}e} \StringTok{\textquotesingle{}[Ss]ch[aä]tz\textquotesingle{}}\NormalTok{ HdE}\DataTypeTok{\textbackslash{} }\NormalTok{German.pdf }\AttributeTok{{-}H} \AttributeTok{{-}C}
\end{Highlighting}
\end{Shaded}

\textbf{Quickly eyeballing the number of matches across different texts}

\begin{Shaded}
\begin{Highlighting}[]
 \ExtensionTok{pdfgrep} \AttributeTok{{-}e} \StringTok{\textquotesingle{}[Ss]ch[aä]tz\textquotesingle{}}\NormalTok{ HdE}\DataTypeTok{\textbackslash{} }\NormalTok{German.pdf HdV}\DataTypeTok{\textbackslash{} }\NormalTok{German.pdf }\AttributeTok{{-}c}
\end{Highlighting}
\end{Shaded}

The result shows that although the HdV and the HdE are comparable in
line count, HdE seems to use the language of treasure more frequently.

\textbf{Dealing with lower quality OCR and spelling variation}

\begin{Shaded}
\begin{Highlighting}[]
 \ExtensionTok{pdfgrep} \PreprocessorTok{*}\NormalTok{.pdf }\AttributeTok{{-}e} \StringTok{\textquotesingle{}G[aei]hen(n)?a\textquotesingle{}} \AttributeTok{{-}{-}page{-}number}\OperatorTok{=}\NormalTok{label }\AttributeTok{{-}H}
\end{Highlighting}
\end{Shaded}

Note that this also searches for a proper name (Gehenna) in multiple
languages.

\textbf{Searching in multiple languages simultaneously}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{pdfgrep} \AttributeTok{{-}i} \AttributeTok{{-}e} \StringTok{\textquotesingle{}([Kk]ingdom)|(Königtum)|([Rr]eich)\textquotesingle{}} \AttributeTok{{-}{-}page{-}number}\OperatorTok{=}\NormalTok{label }\AttributeTok{{-}H} \PreprocessorTok{*}\NormalTok{.pdf}
\end{Highlighting}
\end{Shaded}

The pipe character in a regular expression serves as a logical
\VERB|\ExtensionTok{OR}|.

\textbf{Lookbehinds and pipelines when dealing with many false
positives}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\ExtensionTok{pdfgrep}  \AttributeTok{{-}P} \StringTok{\textquotesingle{}(?\textless{}![Zz]u )Ende(?! des [a{-}z])\textquotesingle{}} 
\ExtensionTok{{-}{-}page{-}number=label} \AttributeTok{{-}H} \AttributeTok{{-}C}\NormalTok{ 3 }
\ExtensionTok{{-}{-}color=always} \PreprocessorTok{*}\NormalTok{.pdf }\KeywordTok{|} \FunctionTok{grep} \AttributeTok{{-}v} \AttributeTok{{-}e} \StringTok{\textquotesingle{}[Zz]u\textquotesingle{}}
\end{Highlighting}
\end{Shaded}

In this example, we find instances of the word Ende but which are not
preceded by the word Zu, because the phrase ``Zu Ende'' is very common
in these translations. It corresponds to \emph{šlem}, a scribal note in
the mss. common at the end of a \emph{madrāšâ} or collection of
\emph{madrāšê}.

Here's a version that omits the \texttt{-C} flag. It is not useful when
using the command in a pipeline to produce a report.

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{pdfgrep}  \AttributeTok{{-}P} \StringTok{\textquotesingle{}(?\textless{}![Zz]u )Ende(?! des [a{-}z])\textquotesingle{}} 
\ExtensionTok{{-}{-}page{-}number=label} \AttributeTok{{-}H}  
\ExtensionTok{{-}{-}color=always} \PreprocessorTok{*}\NormalTok{.pdf }\KeywordTok{|} \FunctionTok{grep} \AttributeTok{{-}v} \AttributeTok{{-}e} \StringTok{\textquotesingle{}[Zz]u\textquotesingle{}}
\end{Highlighting}
\end{Shaded}

\subsection{Report}\label{report}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  repaginate. See
  https://pdfa.org/glossary-of-pdf-terms/\#integer-page-index

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \setcounter{enumii}{3}
  \tightlist
  \item
    For books with distinct pagination of front matter and body text.
    There are two options. In this case I've found a graphical tool
    really is the most efficient. Otherwise edit internal structure
    using qpdf and a plain text editor.
  \item
    For articles and chapters with cover page(s) and pagination
    beginning in the midst of a larger sequence. The best option in this
    case is to use latex. There are several options here:

    \begin{enumerate}
    \def\labelenumiii{\arabic{enumiii}.}
    \tightlist
    \item
      Use a graphical tool, such as PDFExpert, Adobe Reader or MacOS
      Preview. If using MacOS Preview, know that the it must be set to
      use ``logical page numbers.'' Tested tools include: Acrobat
      Reader, Okular, Sumatra, Skim. Skim, Sumatra, and Acrobat Reader
      cannot do it
    \end{enumerate}
  \item
    recombine (most tools I've found don't do this without messing with
    the page labels.)
  \end{enumerate}
\item
  Basic, exploratory searches
\item
  Once you've found things of interest, combine searches into a single
  script, expand searches to more files, and script the results into a
  report.
\end{enumerate}

\section{Notes}\label{notes}

Pdf page labels should be distinguished from any page numbering printed
on the document header or footer. See
\includegraphics{file:///Users/drew/Desktop/Screenshot\%202025-04-16\%20at\%2012.38.19\%E2\%80\%AFPM.png}

Source:
https://helpx.adobe.com/acrobat/using/manipulating-deleting-renumbering-pdf-pages.html?x-product=Helpx\%2F1.0.0\&x-product-location=Search\%3AForums\%3Alink\%2F3.6.7
accessed 2025-04-16

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-pdfassociation2025}
Association, PDF. {``Glossary of PDF Terms.''}
\url{https://pdfa.org/glossary-of-pdf-terms/\#p}, 2025.

\bibitem[\citeproctext]{ref-kernighan1984}
Kernighan, Brian W., and Rob Pike. \emph{The UNIX Programming
Environment}. Englewood Cliffs, New Jersey: Prentice-Hall, 1984.

\bibitem[\citeproctext]{ref-robbins2005}
Robbins, Arnold, and Nelson H. F. Beebe. \emph{Classic Shell Scripting:
Hidden Commands That Unlock the Power of Unix}. Sebastapol, California:
{``O'Reilly Media, Inc.''} 2005.

\end{CSLReferences}

\end{document}
